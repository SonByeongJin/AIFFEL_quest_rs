{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6774587",
   "metadata": {},
   "source": [
    "# transformer 번역기 프로젝트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dbc470",
   "metadata": {},
   "source": [
    "## 프로젝트 목표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95ac05c",
   "metadata": {},
   "source": [
    "1. 번역기 모델 학습에 필요한 텍스트 데이터 전처리가 잘 이루어졌다.\t\n",
    "- 데이터 정제, SentencePiece를 활용한 토큰화 및 데이터셋 구축의 과정이 지시대로 진행되었다.\n",
    "2. Transformer 번역기 모델이 정상적으로 구동된다.\t\n",
    "- Transformer 모델의 학습과 추론 과정이 정상적으로 진행되어, 한-영 번역기능이 정상 동작한다.\n",
    "3. 테스트 결과 의미가 통하는 수준의 번역문이 생성되었다.\t\n",
    "- 제시된 문장에 대한 그럴듯한 영어 번역문이 생성되며, 시각화된 Attention Map으로 결과를 뒷받침한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3192823d",
   "metadata": {},
   "source": [
    "## 코드구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fc9df542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "import sentencepiece as spm\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64120f31",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "23176089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('라라는 또한 멕시코 기자의 죽음에 대해 베네수엘라를 비판하는 멕시코의 시위와 베네수엘라 내부 반 차베스 시위대의 시위를 여과 없이 방영한 CNN을 비난했다.', 'Lara also criticized U.S.-based CNN for broadcasting video showing anti-government demonstrations, followed by images from Acapulco, Mexico, that showed protests against the death of a Mexican journalist and for juxtaposing Chavez with footage showing the body of an alleged al Qaeda leader and protests in China.')\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/transformer/data'\n",
    "kor_path = data_dir+\"/korean-english-park.train.ko\"\n",
    "eng_path = data_dir+\"/korean-english-park.train.en\"\n",
    "\n",
    "# 데이터 정제 및 토큰화\n",
    "def clean_corpus(kor_path, eng_path):\n",
    "    with open(kor_path, \"r\") as f: kor = f.read().splitlines()\n",
    "    with open(eng_path, \"r\") as f: eng = f.read().splitlines()\n",
    "    assert len(kor) == len(eng)\n",
    "\n",
    "    cleaned_corpus = set(zip(kor, eng))\n",
    "\n",
    "    return cleaned_corpus\n",
    "\n",
    "cleaned_corpus = clean_corpus(kor_path, eng_path)\n",
    "print(list(cleaned_corpus)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4953b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    \n",
    "    # 소문자 변환\n",
    "    sentence = sentence.lower().strip()\n",
    "\n",
    "    # 알파벳, 문장부호, 한글만 남기기\n",
    "    # 문장부호 양 옆에 공백 추가하기\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^가-힣a-zA-Z0-9?.!,]+\", \" \", sentence)    \n",
    "    \n",
    "    # 문장 앞뒤 공백제거\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4a7397f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ko_tokenizer_20000_unigram_train.txt\n",
      "  input_format: \n",
      "  model_prefix: ko_tokenizer_20000_unigram\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 20000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: ko_tokenizer_20000_unigram_train.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 78967 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=5192552\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=1679\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 78967 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 162320 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 78967\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 210435\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 210435 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=85366 obj=12.9319 num_tokens=415020 num_tokens/piece=4.86165\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=72615 obj=11.7634 num_tokens=416610 num_tokens/piece=5.73724\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=54456 obj=11.775 num_tokens=434410 num_tokens/piece=7.97727\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=54441 obj=11.7417 num_tokens=434745 num_tokens/piece=7.98562\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=40830 obj=11.8876 num_tokens=459428 num_tokens/piece=11.2522\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=40829 obj=11.8504 num_tokens=459520 num_tokens/piece=11.2547\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=30621 obj=12.0525 num_tokens=486442 num_tokens/piece=15.8859\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=30621 obj=12.0101 num_tokens=486444 num_tokens/piece=15.886\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=22965 obj=12.2566 num_tokens=514328 num_tokens/piece=22.3962\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=22965 obj=12.2091 num_tokens=514421 num_tokens/piece=22.4002\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=22000 obj=12.2535 num_tokens=518304 num_tokens/piece=23.5593\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=22000 obj=12.2457 num_tokens=518304 num_tokens/piece=23.5593\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: ko_tokenizer_20000_unigram.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: ko_tokenizer_20000_unigram.vocab\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: en_tokenizer_20000_unigram_train.txt\n",
      "  input_format: \n",
      "  model_prefix: en_tokenizer_20000_unigram\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 20000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: en_tokenizer_20000_unigram_train.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 78957 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=10789012\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9506% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=38\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999506\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 78957 sentences.\n",
      "uni"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 83783 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 78957\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 46275\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 46275 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=35194 obj=9.97208 num_tokens=87100 num_tokens/piece=2.47485\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=26446 obj=8.1277 num_tokens=87543 num_tokens/piece=3.31025\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=21986 obj=8.04698 num_tokens=88961 num_tokens/piece=4.04626\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=21887 obj=8.02745 num_tokens=89134 num_tokens/piece=4.07246\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: en_tokenizer_20000_unigram.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: en_tokenizer_20000_unigram.vocab\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Sentencepiece를 활용하여 학습한 tokenizer를 생성합니다.\n",
    "def generate_tokenizer(corpus,\n",
    "                        vocab_size,\n",
    "                        lang=\"ko\",\n",
    "                        pad_id=0,\n",
    "                        bos_id=1,\n",
    "                        eos_id=2,\n",
    "                        unk_id=3):\n",
    "\n",
    "    mode = \"unigram\" # BPE 도 됨\n",
    "    model_prefix = f\"{lang}_tokenizer_{vocab_size}_{mode}\"\n",
    "    input_file = f\"{model_prefix}_train.txt\"\n",
    "    \n",
    "    # 한글, 영어 구분\n",
    "    if lang == \"ko\":\n",
    "        lang_num = 1.0\n",
    "    else:\n",
    "        lang_num = 0.9995\n",
    "\n",
    "    # 코퍼스 파일 저장\n",
    "    with open(input_file, 'w', encoding='utf-8-sig') as f:\n",
    "        for line in corpus:\n",
    "            cleaned_line = line.strip()\n",
    "            if cleaned_line:\n",
    "                f.write(cleaned_line + '\\n')\n",
    "\n",
    "    # 토크나이저 학습\n",
    "    spm.SentencePieceTrainer.train(\n",
    "        input=input_file,\n",
    "        model_prefix=model_prefix,\n",
    "        vocab_size=vocab_size,\n",
    "        pad_id=pad_id,\n",
    "        bos_id=bos_id,\n",
    "        eos_id=eos_id,\n",
    "        unk_id=unk_id,\n",
    "        character_coverage=lang_num,\n",
    "        model_type=mode\n",
    "    )\n",
    "\n",
    "    # 토크나이저 로드\n",
    "    tokenizer = spm.SentencePieceProcessor()\n",
    "    tokenizer.load(f\"{model_prefix}.model\")\n",
    "\n",
    "    return tokenizer\n",
    "    \n",
    "\n",
    "SRC_VOCAB_SIZE = TGT_VOCAB_SIZE = 20000\n",
    "\n",
    "eng_corpus = []\n",
    "kor_corpus = []\n",
    "\n",
    "for k, e in cleaned_corpus:\n",
    "    # k, e = pair.split(\"\\t\")\n",
    "\n",
    "    kor_corpus.append(preprocess_sentence(k))\n",
    "    eng_corpus.append(preprocess_sentence(e))\n",
    "\n",
    "ko_tokenizer = generate_tokenizer(kor_corpus, SRC_VOCAB_SIZE, \"ko\")\n",
    "en_tokenizer = generate_tokenizer(eng_corpus, TGT_VOCAB_SIZE, \"en\")\n",
    "en_tokenizer.set_encode_extra_options(\"bos:eos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eaff1986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78968 78968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78968/78968 [00:05<00:00, 14922.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71276 71276\n"
     ]
    }
   ],
   "source": [
    "print(len(kor_corpus), len(eng_corpus))\n",
    "\n",
    "src_corpus = []\n",
    "tgt_corpus = []\n",
    "\n",
    "assert len(kor_corpus) == len(eng_corpus)\n",
    "\n",
    "# 토큰의 길이가 50 이하인 문장만 남깁니다. \n",
    "for idx in tqdm(range(len(kor_corpus))):\n",
    "    # 각각 토크나이저로 인덱스\n",
    "    src_line = ko_tokenizer.encode_as_ids(kor_corpus[idx])\n",
    "    tgt_line = en_tokenizer.encode_as_ids(eng_corpus[idx])\n",
    "\n",
    "    # 길이 필터링(50이하)\n",
    "    if len(src_line) <=50 and len(tgt_line) <=50:\n",
    "        src_corpus.append(src_line)\n",
    "        tgt_corpus.append(tgt_line)  \n",
    "\n",
    "# 패딩처리를 완료하여 학습용 데이터를 완성합니다. \n",
    "enc_train = tf.keras.preprocessing.sequence.pad_sequences(src_corpus, padding='post')\n",
    "dec_train = tf.keras.preprocessing.sequence.pad_sequences(tgt_corpus, padding='post')\n",
    "\n",
    "print(len(enc_train), len(dec_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4ea52f",
   "metadata": {},
   "source": [
    "### 모델설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "96101f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, int(i) / d_model)\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "98abb095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "#     def __init__(self, d_model, num_heads):\n",
    "#         super(MultiHeadAttention, self).__init__()\n",
    "#         self.num_heads = num_heads\n",
    "#         self.d_model = d_model\n",
    "\n",
    "#         self.depth = d_model // self.num_heads\n",
    "\n",
    "#         self.W_q = tf.keras.layers.Dense(d_model)\n",
    "#         self.W_k = tf.keras.layers.Dense(d_model)\n",
    "#         self.W_v = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "#         self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "#     def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "#         d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "#         QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "#         scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "#         if mask is not None: scaled_qk += (mask * -1e9)\n",
    "\n",
    "#         attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "#         out = tf.matmul(attentions, V)\n",
    "\n",
    "#         return out, attentions\n",
    "\n",
    "\n",
    "#     def split_heads(self, x):\n",
    "# #         batch_size = x.shape[0]\n",
    "#         batch_size = tf.shape(x)[0]\n",
    "#         seq_len = tf.shape(x)[1]\n",
    "#         split_x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "#         split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "#         return split_x\n",
    "\n",
    "#     def combine_heads(self, x):\n",
    "# #         batch_size = x.shape[0]\n",
    "#         batch_size = tf.shape(x)[0]\n",
    "#         seq_len = tf.shape(x)[2]\n",
    "#         combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "#         combined_x = tf.reshape(combined_x, (batch_size, -1, self.d_model))\n",
    "\n",
    "#         return combined_x\n",
    "\n",
    "\n",
    "#     def call(self, Q, K, V, mask):\n",
    "#         WQ = self.W_q(Q)\n",
    "#         WK = self.W_k(K)\n",
    "#         WV = self.W_v(V)\n",
    "\n",
    "#         WQ_splits = self.split_heads(WQ)\n",
    "#         WK_splits = self.split_heads(WK)\n",
    "#         WV_splits = self.split_heads(WV)\n",
    "\n",
    "#         out, attention_weights = self.scaled_dot_product_attention(\n",
    "#             WQ_splits, WK_splits, WV_splits, mask)\n",
    "\n",
    "#         out = self.combine_heads(out)\n",
    "#         out = self.linear(out)\n",
    "\n",
    "#         return out, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e2fae8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "\n",
    "        self.depth = d_model // num_heads\n",
    "\n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(tf.shape(K)[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None:\n",
    "            # mask shape: (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "            scaled_qk += (mask * -1e9)\n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # (batch_size, seq_len, num_heads, depth)\n",
    "        split_x = tf.reshape(x, (batch_size, seq_len, self.num_heads, self.depth))\n",
    "\n",
    "        # (batch_size, num_heads, seq_len, depth)\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        seq_len = tf.shape(x)[2]\n",
    "\n",
    "        # (batch_size, seq_len, num_heads, depth)\n",
    "        x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # (batch_size, seq_len, d_model)\n",
    "        combined_x = tf.reshape(x, (batch_size, seq_len, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "\n",
    "    def call(self, Q, K, V, mask):\n",
    "        WQ = self.W_q(Q)  # (batch_size, seq_len_q, d_model)\n",
    "        WK = self.W_k(K)  # (batch_size, seq_len_k, d_model)\n",
    "        WV = self.W_v(V)  # (batch_size, seq_len_v, d_model)\n",
    "\n",
    "        WQ_splits = self.split_heads(WQ)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        WK_splits = self.split_heads(WK)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        WV_splits = self.split_heads(WV)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask\n",
    "        )\n",
    "\n",
    "        out = self.combine_heads(out)  # (batch_size, seq_len_q, d_model)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5e422b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.w_1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.w_2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.w_1(x)\n",
    "        out = self.w_2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e20e3a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1100cafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Masked Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, causality_mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out, dec_enc_attn = self.enc_dec_attn(out, enc_out, enc_out, padding_mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "de114625",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout)\n",
    "                        for _ in range(n_layers)]\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "\n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "\n",
    "        return out, enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "482a8762",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout)\n",
    "                            for _ in range(n_layers)]\n",
    "\n",
    "\n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "        out = x\n",
    "\n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "936e0299",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    src_vocab_size,\n",
    "                    tgt_vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout=0.2,\n",
    "                    shared=True):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared = shared\n",
    "\n",
    "        if shared: self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared: out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "\n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
    "\n",
    "        logits = self.fc(dec_out)\n",
    "\n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f55ef28",
   "metadata": {},
   "source": [
    "### 모델 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5d49f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_MODEL = 512\n",
    "transformer = Transformer(\n",
    "                    n_layers=2,\n",
    "                    d_model=D_MODEL,\n",
    "                    n_heads=8,\n",
    "                    d_ff=256,\n",
    "                    src_vocab_size= SRC_VOCAB_SIZE,\n",
    "                    tgt_vocab_size= TGT_VOCAB_SIZE,\n",
    "                    pos_len = 50,\n",
    "                    dropout=0.2,\n",
    "                    shared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6e91d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2d002d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model=D_MODEL)\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "53081224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEGCAYAAABYV4NmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAxj0lEQVR4nO3de3xdVZ3//9cnJ7embZI2TUuvtLSFUuQeQAR0uEnR0Y5OHYvOgIo/xvnC6OjMODDj12H4Dj6GcZTvqPgVFBQRLYi3iiijcpOLbYNAgUIllEJbSu9p07Q5yUk+vz/2Snoazsk5OT07p0nez8fjPM4+a6+99tonyf5kr7X22ubuiIiIFFtZqSsgIiIjkwKMiIjEQgFGRERioQAjIiKxUIAREZFYlJe6AqU0adIknz17dqmrISIyrDz55JPb3b0xV75RHWBmz55Nc3NzqashIjKsmNmr+eRTE5mIiMRCAUZERGKhACMiIrFQgBERkVgowIiISCxiDTBmtsjM1ppZi5ldnWF9lZndFdavMLPZaeuuCelrzeyiXGWa2e/M7Onwet3MfhrnsYmIyMBiG6ZsZgngJuBCYCOwysyWu/uatGyXA7vcfZ6ZLQVuAD5oZguBpcBxwDTgN2Z2dNgmY5nufk7avn8E/CyuYxMRkdzivII5HWhx93Xu3gksAxb3y7MYuD0s3wOcb2YW0pe5e9LdXwFaQnk5yzSzWuA84KfxHFZ2L2/by+Mt24d6tyIih6U4A8x0YEPa540hLWMed08Bu4GGAbbNp8w/A37r7nsyVcrMrjCzZjNr3rZt22COJ6fzv/QwH/rWiqKWKSIyXI3ETv5LgB9kW+nut7h7k7s3NTbmnOlAREQKFGeA2QTMTPs8I6RlzGNm5UAdsGOAbQcs08wmETWj/aIoR1Cgjq7uUu5eROSwEGeAWQXMN7M5ZlZJ1Gm/vF+e5cBlYXkJ8IBHz3BeDiwNo8zmAPOBlXmUuQS41907YjuqPOze31XK3YuIHBZiG0Xm7ikzuwq4H0gAt7n782Z2HdDs7suBW4E7zKwF2EkUMAj57gbWACngSnfvBshUZtpulwL/Edcx5at1XxdTaqtLXQ0RkZKKdTZld78PuK9f2ufTljuAD2TZ9nrg+nzKTFv3J4dQ3aJp3ddZ6iqIiJTcSOzkL7lWNZGJiCjAFFNlefR17t6nACMiogBTRGMqEgC07lcTmYiIAkwRlZcZEHXyi4iMdgowRdSZ6gHUByMiAgowRZXsjgKM+mBERBRgisbd065g1AcjIqIAUyTJEFxAfTAiIqAAUzQKMCIiB1OAKZJkKprgsqq8THfyi4igAFM0ya7oCmZqXTXtnd2aUVlERj0FmCLpbSKbVj8GgB3tuooRkdFNAaZIepvI+gLM3mQpqyMiUnIKMEXSewUzPQSY7QowIjLKKcAUSeebAoyayERkdFOAKZL+fTC6ghGR0U4BpkiSYdRYfU0FNZUJdugKRkRGOQWYIum9gqmuKGPSuCp18ovIqKcAUyS9AaYykaBhXKX6YERk1Is1wJjZIjNba2YtZnZ1hvVVZnZXWL/CzGanrbsmpK81s4tylWmR683sj2b2gpl9Ms5j66/vTv5wBaM+GBEZ7WILMGaWAG4CLgYWApeY2cJ+2S4Hdrn7POBG4Iaw7UJgKXAcsAj4upklcpT5EWAmsMDdjwWWxXVsmfTeyV9VXsYkXcGIiMR6BXM60OLu69y9k+iEv7hfnsXA7WH5HuB8M7OQvszdk+7+CtASyhuozL8BrnP3HgB33xrjsb1JbxNZVXmChrFV7GxP0tPjQ1kFEZHDSpwBZjqwIe3zxpCWMY+7p4DdQMMA2w5U5lzgg2bWbGa/NLP5mSplZleEPM3btm0r6MAy6b0PprK8jMbxVfQ47NSklyIyio2kTv4qoMPdm4BvArdlyuTut7h7k7s3NTY2Fm3nyVQ3FQkjUWZMqa0G4I3dHUUrX0RkuIkzwGwi6hPpNSOkZcxjZuVAHbBjgG0HKnMj8OOw/BPghEM+gkFIpnqoKk8A0YzKoAAjIqNbnAFmFTDfzOaYWSVRp/3yfnmWA5eF5SXAA+7uIX1pGGU2B5gPrMxR5k+Bc8PyO4A/xnNYmSVT3VSVR1/nESHAbN6jACMio1d5XAW7e8rMrgLuBxLAbe7+vJldBzS7+3LgVuAOM2sBdhIFDEK+u4E1QAq40t27ATKVGXb5H8CdZvZpYC/w8biOLZNkV09fgJk0ropEmbFFVzAiMorFFmAA3P0+4L5+aZ9PW+4APpBl2+uB6/MpM6S3Au8+tBoXLpnqoTIEmESZMWV8FZsVYERkFBtJnfwlFTWRJfo+T6mr5o09+0tYIxGR0lKAKZJkqoeqigNf59S6anXyi8iopgBTJOl9MABTahVgRGR0U4Apks7unoOayKbWVdPe2U1bR1cJayUiUjoKMEWSPkwZ4Ii66MFjuooRkdFKAaZIkl0H98FMC/fCbGpVR7+IjE4KMEWSfic/wMyJNQBs2KUAIyKjkwJMkSRT3VQmDnydjeOqqCwvY8POfSWslYhI6SjAFEn/YcplZcbMCWMUYERk1FKAKZL+w5QhaiZ7TQFGREYpBZgi6X8nP8DMCTW6ghGRUUsBpghS3T30OG+6gpk1sYY9HSl279O9MCIy+ijAFEHf45Ir+jeRRffCbNilqxgRGX0UYIqgL8D0byLrHaqsZjIRGYUUYIogmeoG3txE1htgXlWAEZFRSAGmCJJdmZvIaqsraBhbyfrt7aWolohISSnAFEFvE1llIvGmdXMnj+PlbXuHukoiIiWnAFME2ZrIAOY2juPlbbqCEZHRRwGmCLKNIgOY2ziWne2d7GzvHOpqiYiUVKwBxswWmdlaM2sxs6szrK8ys7vC+hVmNjtt3TUhfa2ZXZSrTDP7jpm9YmZPh9dJcR5bur4+mPLMTWSAmslEZNSJLcCYWQK4CbgYWAhcYmYL+2W7HNjl7vOAG4EbwrYLgaXAccAi4OtmlsijzH9095PC6+m4jq2/zu7sTWTzGkOA2aoAIyKjS5xXMKcDLe6+zt07gWXA4n55FgO3h+V7gPPNzEL6MndPuvsrQEsoL58yh1y2UWQA0+vHUFVepisYERl14gww04ENaZ83hrSMedw9BewGGgbYNleZ15vZajO70cyqMlXKzK4ws2Yza962bdvgjyqDbDdaQjSr8lHq6BeRUWgkdfJfAywATgMmAv+UKZO73+LuTe7e1NjYWJQdDzSKDGDe5HH8cUtbUfYlIjJcxBlgNgEz0z7PCGkZ85hZOVAH7Bhg26xluvtmjySBbxM1pw2JvvtgsgSYY6eOZ+Ou/ezer0kvRWT0iDPArALmm9kcM6sk6rRf3i/PcuCysLwEeMDdPaQvDaPM5gDzgZUDlWlmU8O7AX8GPBfjsR3kwCiybAGmFoAXN+8ZqiqJiJRceVwFu3vKzK4C7gcSwG3u/ryZXQc0u/ty4FbgDjNrAXYSBQxCvruBNUAKuNLduwEylRl2eaeZNQIGPA18Iq5j6+9AE9mb+2AAjgsBZs3mPZxxVMNQVUtEpKRiCzAA7n4fcF+/tM+nLXcAH8iy7fXA9fmUGdLPO9T6FiqZ6sEMKhKWcX3j+Coaxlbygq5gRGQUGUmd/CXTmYoelxy1zr2ZmbFwWi1rFGBEZBRRgCmCZKona/NYr4VTa/njG3vp6u4ZolqJiJSWAkwRJFPdWTv4ex07tZbO7h5adEe/iIwSCjBFkOzqyXgXf7rjZ9QBsHpj6xDUSESk9BRgiiCfJrI5DWOpG1PBU6+1Dk2lRERKLGeAMbOjzey3ZvZc+HyCmX0u/qoNH8lUN5WJgb/KsjLjpJn1PL2hdWgqJSJSYvlcwXyTaBqWLgB3X024X0UiyVTuJjKAk2fVs3ZLG3uTqSGolYhIaeUTYGrcfWW/NJ0h0yS7enJ28gOcPGsC7rBaVzEiMgrkE2C2m9lcwAHMbAmwOdZaDTPRKLKB+2AATppRD8BTCjAiMgrkcyf/lcAtwAIz2wS8Anw41loNM8lUflcwdTUVzG0cy5Ov7hqCWomIlFY+Acbd/QIzGwuUuXtbmIBSgs5UD1UVua9gAE6f08C9z7xOqruH8hwDA0REhrN8znA/AnD3dnfvfajJPfFVafjJ9woG4My5DbQlUzz/uqaNEZGRLesVjJktAI4D6szs/WmraoHquCs2nORzJ3+vtx41EYAn1u3gxJn1MdZKRKS0BjorHgP8KVAPvCftdQrw/8Ves2Ek2dWT9WFj/U0eX838yeN4/OUdMddKRKS0sl7BuPvPgJ+Z2Znu/sQQ1mnYyedO/nRnzm3gnic30tXdQ4X6YURkhMrn7PaUmV1pZl83s9t6X7HXbJjo6XE6u/PvgwE486gG9nV284yGK4vICJbPWfEO4AjgIuBhYAbQNuAWo0hnmH4/nzv5e71t7iQSZcZDa7fFVS0RkZLL56w4z93/N9Du7rcD7wbOiLdaw0cyFQLMIJrI6moqOPXICfz2xa1xVUtEpOTyCTBd4b3VzN4C1AGT46vS8JJMdQMMqokM4PwFk3lh8x42794fR7VEREoun7PiLWY2AfgcsBxYA9wQa62GkWRX7xXMIAPMsVGMfkBXMSIyQuU8K7r7t9x9l7s/4u5Huftk4Jf5FG5mi8xsrZm1mNnVGdZXmdldYf0KM5udtu6akL7WzC4aRJlfMbMhe2xkXxNZnnfy95rbOI6ZE8fwwAsKMCIyMg0YYMzsTDNbYmaTw+cTzOz7wGO5CjazBHATcDGwELjEzBb2y3Y5sMvd5wE3Eq6MQr6lRDd6LgK+bmaJXGWaWRMwIfdhF0+hTWRmxvkLpvBoy3baNX2/iIxAWc+KZvZF4Dbgz4FfmNm/A/8DrADm51H26UCLu69z905gGbC4X57FwO1h+R7gfDOzkL7M3ZPu/grQEsrLWmYIPl8EPptH3Yqm9wom3xst0138liNIpnr4zQtbil0tEZGSG2iyy3cDJ7t7R+iD2QC8xd3X51n29LBNr428efRZXx53T5nZbqAhpP++37bTw3K2Mq8Clrv75ihGZWZmVwBXAMyaNSvPQ8mu0D4YgNNmT2RKbRX3rt7M4pOm595ARGQYGeis2OHuHQDuvgt4aRDBZUiZ2TTgA8BXc+V191vcvcndmxobGw953weayAbXBwPRY5TfdfxUHl67jbaOrtwbiIgMIwMFmKPMbHnvC5jT73Mum4CZaZ9nhLSMecysnGgI9I4Bts2WfjIwD2gxs/VAjZm15FHHQ3bgPpjCpnz50xOm0dndw6/XqJlMREaWgZrI+veXfGmQZa8C5odnx2wi6rT/UL88y4HLgCeAJcAD7u4hgH3fzL4MTCPq81kJWKYy3f15otkGADCzvWHgQOw6Q4CpHsSd/OlOmVXP9Pox/Ozp13n/KTOKWTURkZIaaLLLhw+l4NCnchVwP5AAbnP3583sOqDZ3ZcDtwJ3hKuNnUQBg5DvbqJ7blLAle7eDZCpzEOp56Eq5E7+dGbG+0+ZztcebOH11v1Mqx9TzOqJiJRMPk+0LJi73wfc1y/t82nLHUR9J5m2vR64Pp8yM+QZV0h9C1HoMOV0f9E0k68+0MI9T27kk+fnM0BPROTwp7niD9GBUWSFXcEAzJxYw9nzJnHXqg309HixqiYiUlIKMIfoUO6DSfcXp81kU+t+Hnt5ezGqJSJScjmbyMzs50D/f6t3A83Azb1DmUer3iayQw0w71w4hQk1FXz3iVc5Z/6hD58WESm1fM6K64C9wDfDaw/R82CODp9HtWSqh4qEkSjLfnNnPqorEnz4jCP5zQtbWL+9vUi1ExEpnXwCzNvc/UPu/vPw+kvgNHe/Ejgl5vod9pJdg3tc8kAuPfNIysuM7zy+vijliYiUUj4BZpyZ9c2pEpZ7R2l1xlKrYaSzu/uQRpClm1xbzXtOnMbdzRvYvV939ovI8JbPmfHvgUfN7EEzewj4HfAPZjaWAxNVjlrRFUzxxkpcfvYc9nV2c+eKV4tWpohIKeTs5Hf3+8xsPrAgJK1N69j/v3FVbLhIpnoG/SyYgRw3rY53HN3INx9Zx6VnzmZcVay3KomIxCbff71PJXo2y4nAX5jZpfFVaXhJporXRNbr0xceza59XdyuvhgRGcZynhnN7A7gv4CzgdPCqynmeg0byVRxm8gATppZz7nHNPLN363TLMsiMmzl0/7SBCx0d91inkGyq+eQ74HJ5FMXHM2f3fQYtz26nk9doOljRGT4yefM+BxpMxXLwaImsuL1wfQ6aWY9Fx03hZsfeZkte0b1vawiMkzlE2AmAWvM7P5BPg9mVIijiazXP7/rWLq6e/ji/WtjKV9EJE75NJFdG3clhrNoFFk8AebIhrF87Kw53PzIOi47czbHz6iLZT8iInHIeWZ094czvYaicsNBZ6p4d/JncuV582gYW8m/Ln9OMy2LyLCSNcCY2aPhvc3M9qS92sxsz9BV8fAWxzDldLXVFfzzu47lD6+18j3dfCkiw0jWM6O7nx3ex7t7bdprvLvXDl0VD29x9sH0ev8p0zln/iRu+OWLbGrdH+u+RESKJa8zo5klzGyamc3qfcVdseEi2VXcO/kzMTO+8L7j6XH43E+eRSPGRWQ4yOdGy78FtgC/Bn4RXvfGXK9hwd1JprqpTMT/3LaZE2v4x4uO4cG127hzxWux709E5FDlc2b8FHCMux/n7seH1wn5FG5mi8xsrZm1mNnVGdZXmdldYf0KM5udtu6akL7WzC7KVaaZ3Wpmz5jZajO7x8zGEbNUj9PjxN5E1usjb5vNOfMn8X/uXcNLW9qGZJ8iIoXK58y4gegJloNiZgngJuBiYCFwiZkt7JftcmCXu88DbgRuCNsuBJYSzX+2CPh6aKYbqMxPu/uJIfi9Blw12DoPVu/jkuMaptxfWZnxpb84kfHV5fztD56io6t7SPYrIlKIfJ9o+VC4ovhM7yuP7U4HWtx9nbt3AsuAxf3yLObAlP/3AOebmYX0Ze6edPdXgJZQXtYy3X0PQNh+DG9+zHPRJcMJPs5hyv1NHl/NFz9wIi++0ca1y59Xf4yIHLbyCTCvEfW/VALj0165TCe6+um1MaRlzOPuKaIrpYYBth2wTDP7NvAG0aMFvpqpUmZ2hZk1m1nztm3b8jiM7Dq7wxXMEDWR9Tr3mMlcee5clq3awPd+r6HLInJ4GvBO/tAkdbS7f3iI6nNI3P2joc5fBT4IfDtDnluAWwCampoO6d//ZNfQNpGl+/sLj+HFzW3828/XMH/KeN56VMOQ10FEZCADnhndvRs40swqCyh7EzAz7fOMkJYxj5mVA3XAjgG2zVlmqPMy4M8LqPOg9PXBDGETWa+yMuPGpScxq6GGv/nek6zbtnfI6yAiMpB8+2AeM7P/Pcg+mFXAfDObEwLUUqD/JJnLgcvC8hLggfBYgOXA0jDKbA4wH1iZrUyLzIO+Ppj3Ai/mUcdDkkz19sEM/RUMRHf533bZaZSZceltK9mqWZdF5DCSz5nxZaL7XsoYRB9M6FO5CrgfeAG4292fN7PrzOy9IdutQIOZtQCfAa4O2z4P3A2sAX4FXOnu3dnKBAy43cyeBZ4FpgLX5XFsh6SUVzC9Zk8ay7c/eho72zu57Nur2KMHlInIYcJG8yikpqYmb25uLnj7R1/azl/euoK7//pMTp8zsYg1G7xH/riNj31nFSfOrOc7Hz2N8dUVJa2PiIxcZvaku+d8snE+d/I3mtkXzew+M3ug91Wcag5vpW4iS/f2oxv56iUn88yGVi67baUetSwiJZfPmfFOov6MOcC/AeuJ+kJGvaG+0TKXi4+fytc+dDKrN+7m0ttWqrlMREoqnzNjg7vfCnSFZ8F8DDgv5noNCweuYErXB9PfordM5WsfOoVnN+7mgzf/Xo9bFpGSySfA9P4bvNnM3m1mJwOl7XA4THSmSnOjZS6L3nIE37qsiVd3tPP+rz9Oy1YNYRaRoZfPmfHfzawO+HvgH4BvAZ+OtVbDRPIwDTAAf3LMZO664kySqW6WfONxVqzbUeoqicgok88jk+91993u/py7n+vup7p7//tZRqUDd/IfPk1k6Y6fUceP/+YsJtZU8uFvreC7T6zX3GUiMmTyGUV2tJn91syeC59PMLPPxV+1w9/hNIosm1kNNfzkyrN4x9GNfP5nz/PZe1ZrFmYRGRL5nBm/CVxD6Itx99VEd9CPeslUD2ZQXmalrsqA6sZU8M1Lm/jk+fP54ZMbWfKNx3lZU8uISMzyCTA17r6yX1oqjsoMN8lUD1XlZUSz0xzeysqMz1x4NN+6tImNu/bzp195lLtXbVCTmYjEJp8As93M5hKer2JmS4DNsdZqmEh2dR9WQ5TzccHCKfzqU2/n5Fn1fPZHq7ny+39gZ3tnqaslIiNQPgHmSuBmYIGZbQL+DvhEnJUaLnqvYIabI+qq+d7lZ3D1xQv49ZotXPjlh/nZ05t0NSMiRZXPKLJ17n4B0AgscPezgffFXrNhoDPVc9jcxT9YZWXGJ94xl5//7dnMmFjDp5Y9zcdvb+b11v2lrpqIjBB5nx3dvd3d28LHfKbrH/GiK5jh1UTW34Ijavnx37yNz737WB5/eQcXfPlhbnqwRSPNROSQFfrv9+Hfqz0EkqnuYdlE1l+izPj4OUfxP59+O2fPm8QX71/LO298hPuff0PNZiJSsELPjjrrMHz7YLKZObGGWy5t4nuXn0F1RRl/fceT/OWtK3hmQ2upqyYiw1DWs6OZtZnZngyvNmDaENbxsJXsGv5NZJmcPX8S933yHK59z0Je2NzG4pse44rvNvPiG3tKXTURGUayBhh3H+/utRle4929fCgrebhKprqpHEFXMOnKE2V85Kw5PPLZc/nMhUfzxMs7uPi/f8cnf/AUL21py12AiIx6ChSHYKQ1kWUyrqqcT54/n0vPPJKbH1nHdx5bz/JnXueCYyfziXfMpWm2JtYWkcxG9tkxZslUz2E70WWx1ddU8k+LFvDY1efxqfPn0/zqLpZ84wmW/L/H+c2aLfT0qFtORA4Wa4Axs0VmttbMWszs6gzrq8zsrrB+hZnNTlt3TUhfa2YX5SrTzO4M6c+Z2W1mFvtD6TtHwRVMfxPHVvLpC4/m8avP41/fs5DNuzv4+HebOe9LD/Gt362jdZ9mBRCRSGxnRzNLADcBFwMLgUvMbGG/bJcDu9x9HnAjcEPYdiHRhJrHAYuAr5tZIkeZdwILgOOBMcDH4zq2XiNlmHIhairL+ehZc3joH/+E/156EpPGVfHvv3iBM77wWz57zzM8u3F3qasoIiUWZx/M6UCLu68DMLNlwGJgTVqexcC1Yfke4GsWzRy5GFjm7kngFTNrCeWRrUx3v6+3UDNbCcyI68B6jdRRZINRkShj8UnTWXzSdNa8vofvrXiVnz61ibubN/KW6bX8+SkzeO+J02gYV1XqqorIEIvz3+/pwIa0zxtDWsY87p4CdgMNA2ybs8zQNPZXwK8yVcrMrjCzZjNr3rZt2yAP6WDJYTxVTBwWTqvlC+87nt//8/lc+57owvLffr6GM77wWz5+ezO/em5z32OmRWTkG4mjyL4OPOLuv8u00t1vAW4BaGpqKrhnuqfH6ewefX0w+aitruAjZ83hI2fNYe0bbfzoDxv5yVOb+M0LW6ivqeCihUfwrhOm8ra5DVQk9P2JjFRxBphNwMy0zzNCWqY8G82sHKgDduTYNmuZZvavRJNy/nUR6j+gzu7oP/GReh9MsRxzxHj++V3H8tmLjuF3Ldv56VObuHf169zVvIH6mgreuXAKFx8/lbPmTtJ3KTLCxBlgVgHzzWwOURBYCnyoX57lwGXAE8AS4AF3dzNbDnzfzL5MNGvAfGAl0RxoGcs0s48DFwHnu3vs7TDJrmgXo70PJl/liTLOPWYy5x4zmY6ubn730nbue3Yzv3z2De5u3khtdTkXHDuFcxdM5u1HN1I3JvZBgCISs9gCjLunzOwq4H4gAdzm7s+b2XVAs7svB24F7gid+DsJj2IO+e4mGhCQAq50926ATGWGXX4DeBV4Ijxh8sfufl1cx5dMRbMNq4ls8KorEly4cAoXLpxCMtXNoy9t5xfPbubBF7fy46c2kSgzTps9gfMWTOa8BVOY2zh2WDw1VEQOZqN5ttympiZvbm4uaNsNO/dxzn8+yBeXnMAHmmbm3kBy6u5xnt6wi9++sJUHXtzKi29EU9LMnDiGs+dN4qx5k3jb3ElMHFtZ4pqKjG5m9qS7N+XKNxI7+YdEMoyGGi138g+FRJlx6pETOfXIiXx20QI2te7ngRe38vDabdz7zGZ+sDIaQLhwai1nzWvgrHmTOH3ORGoq9WsscjjSX2aB1EQWv+n1Y/irtx7JX731SFLdPazetJvHW7bzaMt2bn/8Vb75u1eoSBgnzKinafYETjtyIqceOYEJusIROSwowBSo7wpGAWZIlCfKOGXWBE6ZNYGrzpvP/s5uVq3fyWMvb2fVKzu57dFXuPnhdQDMnzyOptkTOW32BE6bPZEZE8aoD0ekBBRgCqRRZKU1pjLB249u5O1HNwLQ0dXNMxtaaX51F6vW7+TeZ17nBytfA2DSuEpOnFHPCTPqOWFmHSfOqFc/jsgQUIApUG8Tme7dODxUVyQ446gGzjiqAYgGDPxxSxvN63fy9IbdPLOxlQfWbqV3TMvMiWM4cUZ9CDx1HDutltpqDY0WKSYFmAKpiezwligzjp1ay7FTa/mrM6O0to4untu0h2c2trJ6YytPvdbKvas3920zY8KYvm0WhteMCWMoK1PzmkghFGAK1BtgqjUX2bAxvrqCM+c2cObchr60bW1Jntu0mzWb9/BCeP32hS30Pt5mXFU5C44Y3xd4Fkwdz7zJ43S1I5IHBZgCJbt6R5GpD2Y4axxfxbkLJnPugsl9afs7u1m7pa0v4LyweQ8/eWoTd/z+1b48U2qrmD85CjZzJ49j/uRxzJs8joaxlRpQIBIowBSody4yNZGNPGMqE5w0s56TZtb3pbk7G3ftZ+0bbby0dS8tW/fSsrWNHzZvoL2zuy/fhJoK5oVgM2fSWGY3jGXOpLHMnFhDte6ZklFGAaZAGkU2upgZMyfWMHNiDRcsnNKX7u5s3t1By9a9IfC00bJ1L7967g127etK2x6m1Y2Jgs6kmr7AM3vSWGZOqNFgERmRFGAKdOBOfp0YRjMzY1r9GKbVj+kbMt2rdV8n63fsY/32dl7Z3s76He2s397O8qdfZ09Hqi9fmcHUujHMmDCGmRNrovcJNX3LU2qrSWiggQxDCjAF6humrOeZSBb1NZWcVFN5UFMbRFc9rfu6eCUEnPXb29mwaz8bd+3j0Ze2s6Wtg/QpAisSURCbOaHmoCA0Y0IN0+qraRxXRbl+D+UwpABToGSqh8pEmYawyqCZGRPGVjJhbCWnzJrwpvXJVDevt3awYec+Nu7az4Zd4X3nPn7zwha27+08KH+ZwZTaao6oq2Za3RiOqKtmal01U8OygpCUigJMgZJdPWo3l1hUlSeYMynqo8lkf2c3G0PQ2by7g827D7y/8MYeHnhxK/u7ug/aJlFmTB5f1ReEptRWM7m2isnjq2gcX8Xk8dVMHl9FfU2FRsFJ0SjAFCiZ6tYIMimJMZUJ5k8Zz/wp4zOud3f27E/x+u79vLG748B7awdv7NnPC5v38ODarezr7H7TthUJo3FcFY21UcDpH4Am10afJ42r0uOuJScFmAIlUz0KMHJYMjPqaiqoq6ng2Km1WfO1J1NsbUuydU9H9N6WZFtbkq1tHWxrS/Lajn08+eoudrZ3vmlbM5hYU9kXbCaOraRhXCUNYytp6P2ctlxbXa4ro1FIAaZAyVSPngUjw9rYqnLmVJVnbYrr1ZnqYfveZF8w2rY3ydY9vQGpgx3tnby2cx872zvZm0xlLKMiYSHoVNEwrvKg5YaxlX0BauLYKibUVFBbXaH+zRFAAaZAnWoik1Gisrysbyh2Lh1d3exs72Rneyfb9ybZ2d7Jjr2d7GjvZGd7sm95/Y52du7tPOgm1XRmUDemggk1leE9LIf3CTUV1IX3vjxjKxlbmdCV0mFEAaZAaiITebPqikTewQiigLSjvZOdezvZ3p5kV3snu/Z1sXtf9L5rXye793exbW+Sl7bupXVfV9arJIiulOrGRIGnvqaCujFR8KkdU05tdUVYrqC2uvzA8pgoXcGp+GINMGa2CPhvIAF8y93/o9/6KuC7wKnADuCD7r4+rLsGuBzoBj7p7vcPVKaZXQX8HTAXaHT37XEeW7KrR3fxixyi6ooE0+vHMD3PgARRk93u/V20hiDUuq+T1hCMWvcf/HlTazSoYc/+LtoGCEwQDffuDTa11VFQOrDcm15O7ZgKxleXM66qgnFV5YyvLg+fyzUUvJ/YAoyZJYCbgAuBjcAqM1vu7mvSsl0O7HL3eWa2FLgB+KCZLQSWAscB04DfmNnRYZtsZT4G3As8FNcxpUumuhlbpQtAkaFWWV5GYxjdNhjdPU5bRxd79qfY09HF7v1d7NnflbbcPz3F1j17o88dXXSE6aEGMqYiwbjqcsaHwDMuBJ7x1f2DUUWUL+SNlisYV1nO2KrEiAlUcZ4hTwda3H0dgJktAxYD6QFmMXBtWL4H+JpF16iLgWXungReMbOWUB7ZynT3p0JajId0QDLVw4SakfFLIDIaJMqM+ppK6msKe5ppMtXdF4T2dqRo60ixN9lFW99y9Grr6DrwuSPF9rZ9fel7k6m+R0EMpKq8jLFVUbAZW1kelssZW5k4+L3/8kF5wvZV5VSVl5Wk+S/OADMd2JD2eSNwRrY87p4ys91AQ0j/fb9tp4flXGUOiWgUmQKMyGhRVZ6gcXxi0FdO6dydfZ3dbwpEbR1RMGpLpmhPpmjvjN73JaO87Z0p9uzvYnPr/r7t25MpUvlEK6Lg2j8QfXXpycxqqCn4WPIx6tp4zOwK4AqAWbNmFVxOdKOl+mBEJH9m1neCn1JbfcjlJVPdtCe704JStLyvM8Xeg9LT10UBaij+QY4zwGwCZqZ9nhHSMuXZaGblQB1RZ/9A2+Yqc0DufgtwC0BTU1N+4T+DqJNfVzAiUjpV5QmqyhNMHFtYs1/c4jxDrgLmm9kcM6sk6rRf3i/PcuCysLwEeMDdPaQvNbMqM5sDzAdW5lnmkOjsVoARERlIbGdId08BVwH3Ay8Ad7v782Z2nZm9N2S7FWgInfifAa4O2z4P3E00IOBXwJXu3p2tTAAz+6SZbSS6qlltZt+K69ggXMHoTn4Rkaxi7YNx9/uA+/qlfT5tuQP4QJZtrweuz6fMkP4V4CuHWOW8uLsmuxQRyUFnyAKkepweRwFGRGQAOkMWoO9xyRpFJiKSlQJMAZLhYU564JiISHY6QxbgwBWMvj4RkWx0hixAX4DRnfwiIlnpDFmAZCpqIlMfjIhIdgowBehUE5mISE46QxZAo8hERHJTgClAskt9MCIiuegMWYADfTD6+kREstEZsgC9TWS6D0ZEJDudIQugUWQiIrkpwBSgrw9GVzAiIlnpDFkA3ckvIpKbzpAF6LsPRs+DERHJSgGmABpFJiKSm86QBUimeigzKC+zUldFROSwpQBTgGSqh6ryBGYKMCIi2SjAFCDZ1a27+EVEctBZsgDJVA+VCX11IiIDifUsaWaLzGytmbWY2dUZ1leZ2V1h/Qozm5227pqQvtbMLspVppnNCWW0hDIr4zquZKpHVzAiIjnEdpY0swRwE3AxsBC4xMwW9st2ObDL3ecBNwI3hG0XAkuB44BFwNfNLJGjzBuAG0NZu0LZsUimunUXv4hIDnH+G3460OLu69y9E1gGLO6XZzFwe1i+Bzjfop7zxcAyd0+6+ytASygvY5lhm/NCGYQy/yyuA0t29WiIsohIDuUxlj0d2JD2eSNwRrY87p4ys91AQ0j/fb9tp4flTGU2AK3unsqQ/yBmdgVwBcCsWbMGd0TBKUdOYG8ylTujiMgoFmeAOSy5+y3ALQBNTU1eSBlXnjuvqHUSERmJ4mzn2QTMTPs8I6RlzGNm5UAdsGOAbbOl7wDqQxnZ9iUiIkMozgCzCpgfRndVEnXaL++XZzlwWVheAjzg7h7Sl4ZRZnOA+cDKbGWGbR4MZRDK/FmMxyYiIjnE1kQW+lSuAu4HEsBt7v68mV0HNLv7cuBW4A4zawF2EgUMQr67gTVACrjS3bsBMpUZdvlPwDIz+3fgqVC2iIiUiEX//I9OTU1N3tzcXOpqiIgMK2b2pLs35cqnsbYiIhILBRgREYmFAoyIiMRCAUZERGIxqjv5zWwb8GqBm08CthexOsWieg2O6jU4qtfgjNR6HenujbkyjeoAcyjMrDmfURRDTfUaHNVrcFSvwRnt9VITmYiIxEIBRkREYqEAU7hbSl2BLFSvwVG9Bkf1GpxRXS/1wYiISCx0BSMiIrFQgBERkXi4u16DfAGLgLVEj3K+OobyZxI9fmAN8DzwqZB+LdFzbp4Or3elbXNNqM9a4KJcdQXmACtC+l1AZZ51Ww88G/bfHNImAr8GXgrvE0K6AV8J+1gNnJJWzmUh/0vAZWnpp4byW8K2lkedjkn7Tp4G9gB/V6rvC7gN2Ao8l5YW+3eUbR8D1OmLwIthvz8B6kP6bGB/2vf2jUL3PdDx5ahb7D87oCp8bgnrZ+dRr7vS6rQeeHoovzOynxtK+vuV9W+h2CfHkf4iekzAy8BRQCXwDLCwyPuY2vuLAIwH/ggsDH90/5Ah/8JQj6rwx/RyqGfWugJ3A0vD8jeAv8mzbuuBSf3S/pPwBw1cDdwQlt8F/DL8kr8VWJH2i7ouvE8Iy71/ECtDXgvbXlzAz+cN4MhSfV/A24FTOPjEFPt3lG0fA9TpnUB5WL4hrU6z0/P1O7ZB7Tvb8eXxfcX+swP+FyEQED0q5K5c9eq3/kvA54fyOyP7uaGkv19Z/xYGe/Ib7S/gTOD+tM/XANfEvM+fARcO8Ed3UB2InpdzZra6hl+c7Rw4uRyUL0dd1vPmALMWmBqWpwJrw/LNwCX98wGXADenpd8c0qYCL6alH5Qvz/q9E3gsLJfs+6LfCWcovqNs+8hWp37r3gfcOVC+Qvad7fjy+L5i/9n1bhuWy0M+G6heaekGbADml+o7C+t6zw0l//3K9FIfzOBNJ/rF6rUxpMXCzGYDJxNdwgNcZWarzew2M5uQo07Z0huAVndP9UvPhwP/Y2ZPmtkVIW2Ku28Oy28AUwqs1/Sw3D99MJYCP0j7XOrvq9dQfEfZ9pGPjxH9t9prjpk9ZWYPm9k5aXUd7L4P5e8l7p9d3zZh/e6QPx/nAFvc/aW0tCH9zvqdGw7L3y8FmMOYmY0DfgT8nbvvAf4fMBc4CdhMdIk+1M5291OAi4Erzezt6Ss9+vfGS1AvwmO03wv8MCQdDt/XmwzFdzSYfZjZvxA9OfbOkLQZmOXuJwOfAb5vZrVx7HsAh+XPLs0lHPyPzJB+ZxnODQWXVYh896EAM3ibiDraes0IaUVlZhVEv0B3uvuPAdx9i7t3u3sP8E3g9Bx1ypa+A6g3s/J+6Tm5+6bwvpWoY/h0YIuZTQ31nkrUMVpIvTaF5f7p+boY+IO7bwl1LPn3lWYovqNs+8jKzD4C/Cnw4XDSwN2T7r4jLD9J1LdxdIH7LujvZYh+dn3bhPV1If+AQt73E3X499Z3yL6zTOeGAsoakt8vBZjBWwXMN7M54T/mpcDyYu7AzAy4FXjB3b+clj41Ldv7gOfC8nJgqZlVmdkcYD5RR13GuoYTyYPAkrD9ZURtubnqNdbMxvcuE/V3PBf2f1mGspYDl1rkrcDucIl9P/BOM5sQmj7eSdQuvhnYY2ZvDd/BpfnUK81B/1WW+vvqZyi+o2z7yMjMFgGfBd7r7vvS0hvNLBGWjwrfz7oC953t+AY0RD+79DovAR7oDbI5XEDUT9HXlDRU31m2c0MBZcX++wWok7+QF9HIjD8S/ZfyLzGUfzbR5edq0oZpAncQDR9cHX7YU9O2+ZdQn7WkjbzKVlei0TYriYYi/hCoyqNeRxGNznmGaIjkv4T0BuC3RMMXfwNMDOkG3BT2/SzQlFbWx8K+W4CPpqU3EZ1MXga+Rh7DlMN2Y4n++6xLSyvJ90UU5DYDXURt2JcPxXeUbR8D1KmFqB2+93esd0TVn4ef79PAH4D3FLrvgY4vR91i/9kB1eFzS1h/VK56hfTvAJ/ol3dIvjOynxtK+vuV7aWpYkREJBZqIhMRkVgowIiISCwUYEREJBYKMCIiEgsFGBERiYUCjMggmVmDmT0dXm+Y2aa0z5U5tm0ys68Mcn8fM7NnLZo25TkzWxzSP2Jm0w7lWETipGHKIofAzK4F9rr7f6WllfuBua8OtfwZwMNEM+juDlOENLr7K2b2ENGEkM3F2JdIsekKRqQIzOw7ZvYNM1sB/KeZnW5mT1g0+eHjZnZMyPcnZnZvWL7WookcHzKzdWb2yQxFTwbagL0A7r43BJclRDfE3RmunMaY2akWTbT4pJndbwem9XjIzP475HvOzE7PsB+RolOAESmeGcDb3P0zRA/yOsejyQ8/D3whyzYLgIuI5tr6V4vmmUr3DLAFeMXMvm1m7wFw93uAZqI5xE4imqzyq8ASdz+V6GFZ16eVUxPy/a+wTiR25bmziEiefuju3WG5DrjdzOYTTe3RP3D0+oW7J4GkmW0lmgK9b44rd+8Oc4adBpwP3Ghmp7r7tf3KOQZ4C/DraAopEkTTnPT6QSjvETOrNbN6d28t/FBFclOAESme9rTl/wM86O7vs+i5HQ9l2SaZttxNhr9JjzpKVwIrzezXwLeJHsiVzoDn3f3MLPvp39mqzleJnZrIROJRx4Fpzj9SaCFmNs3MTklLOgl4NSy3ET02F6KJHxvN7MywXYWZHZe23QdD+tlEM+ruLrROIvnSFYxIPP6TqInsc8AvDqGcCuC/wnDkDmAb8Imw7jvAN8xsP9GjgJcAXzGzOqK/7f9LNMMvQIeZPRXK+9gh1EckbxqmLDLCaTizlIqayEREJBa6ghERkVjoCkZERGKhACMiIrFQgBERkVgowIiISCwUYEREJBb/P5Q5DMNA3+U8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9a22f38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    # Masking 되지 않은 입력의 개수로 Scaling하는 과정\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a7a508cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_padding_mask(seq):\n",
    "#     seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "#     return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "# def generate_causality_mask(size):\n",
    "#     mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "#     return mask  # (seq_len, seq_len)\n",
    "\n",
    "# def generate_masks(src, tgt):\n",
    "#     enc_mask = generate_padding_mask(src)\n",
    "#     dec_mask = generate_causality_mask(tf.shape(tgt)[1])\n",
    "#     dec_enc_mask = generate_padding_mask(src)\n",
    "\n",
    "#     return enc_mask, dec_enc_mask, dec_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ecb1f672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_causality_mask(seq_len, batch_size, num_heads):\n",
    "    # 기본 Look-ahead Mask 생성\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)  # (seq_len, seq_len)\n",
    "\n",
    "    # 4D로 변형 후 batch와 heads 차원에 맞게 타일링\n",
    "    mask = mask[tf.newaxis, tf.newaxis, :, :]  # (1, 1, seq_len, seq_len)\n",
    "    mask = tf.tile(mask, [batch_size, num_heads, 1, 1])  # (batch_size, num_heads, seq_len, seq_len)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def generate_masks(src, tgt, batch_size=1, num_heads=8):\n",
    "    enc_padding_mask = generate_padding_mask(src)\n",
    "    dec_enc_padding_mask = generate_padding_mask(src)\n",
    "\n",
    "    dec_padding_mask = generate_padding_mask(tgt)\n",
    "\n",
    "    seq_len = tf.shape(tgt)[1]\n",
    "    causal_mask = generate_causality_mask(seq_len, batch_size, num_heads)\n",
    "\n",
    "    # Look-ahead + padding mask 결합\n",
    "    combined_mask = tf.maximum(dec_padding_mask, causal_mask)\n",
    "\n",
    "    return enc_padding_mask, dec_enc_padding_mask, combined_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c18fae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Step 함수 정의\n",
    "\n",
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    gold = tgt[:, 1:]\n",
    "        \n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n",
    "\n",
    "    # 계산된 loss에 tf.GradientTape()를 적용해 학습을 진행합니다.\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions[:, :-1])\n",
    "\n",
    "    # 최종적으로 optimizer.apply_gradients()가 사용됩니다. \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "294030ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention 시각화 함수\n",
    "\n",
    "def visualize_attention(src, tgt, enc_attns, dec_attns, dec_enc_attns):\n",
    "    def draw(data, ax, x=\"auto\", y=\"auto\"):\n",
    "        import seaborn\n",
    "        seaborn.heatmap(data, \n",
    "                        square=True,\n",
    "                        vmin=0.0, vmax=1.0, \n",
    "                        cbar=False, ax=ax,\n",
    "                        xticklabels=x,\n",
    "                        yticklabels=y)\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Encoder Layer\", layer + 1)\n",
    "        for h in range(4):\n",
    "            draw(enc_attns[layer][0, h, :len(src), :len(src)], axs[h], src, src)\n",
    "        plt.show()\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Decoder Self Layer\", layer+1)\n",
    "        for h in range(4):\n",
    "            draw(dec_attns[layer][0, h, :len(tgt), :len(tgt)], axs[h], tgt, tgt)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Decoder Src Layer\", layer+1)\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        for h in range(4):\n",
    "            draw(dec_enc_attns[layer][0, h, :len(tgt), :len(src)], axs[h], src, tgt)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c924f7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역 생성 함수\n",
    "\n",
    "def evaluate(sentence, model, src_tokenizer, tgt_tokenizer):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    pieces = src_tokenizer.encode_as_pieces(sentence)\n",
    "    tokens = src_tokenizer.encode_as_ids(sentence)\n",
    "\n",
    "    _input = tf.keras.preprocessing.sequence.pad_sequences([tokens],\n",
    "                                                           maxlen=enc_train.shape[-1],\n",
    "                                                           padding='post')\n",
    "    \n",
    "    ids = []\n",
    "    output = tf.expand_dims([tgt_tokenizer.bos_id()], 0)\n",
    "    for i in range(dec_train.shape[-1]):\n",
    "        batch_size = tf.shape(_input)[0]\n",
    "\n",
    "        enc_padding_mask, dec_enc_padding_mask, combined_mask = \\\n",
    "            generate_masks(_input, output, batch_size=batch_size, num_heads=model.n_heads)\n",
    "\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns =\\\n",
    "        model(_input, \n",
    "              output,\n",
    "              enc_padding_mask,\n",
    "              combined_mask,\n",
    "              dec_enc_padding_mask)\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "        if tgt_tokenizer.eos_id() == predicted_id:\n",
    "            result = tgt_tokenizer.decode_ids(ids)\n",
    "            return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    result = tgt_tokenizer.decode_ids(ids)\n",
    "\n",
    "    return pieces, result, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0ce00b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def translate(sentence, model, src_tokenizer, tgt_tokenizer, plot_attention=False):\n",
    "    pieces, result, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "    evaluate(sentence, model, src_tokenizer, tgt_tokenizer)\n",
    "    \n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    if plot_attention:\n",
    "        visualize_attention(pieces, result.split(), enc_attns, dec_attns, dec_enc_attns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b52983d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1: 100%|██████████| 1114/1114 [02:44<00:00,  6.79it/s, Loss 0.6304]\n",
      "Epoch  2: 100%|██████████| 1114/1114 [02:43<00:00,  6.80it/s, Loss 0.4640]\n",
      "Epoch  3: 100%|██████████| 1114/1114 [02:43<00:00,  6.80it/s, Loss 0.3357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: inginginginginginginginginginginginginginginginginginginginginginginginginginginginginginginginginginginginginginginginginginginginginginginginginging\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: area area area area area area area area area area area area area area area area area area area area area area area area area area area area area area area area area area area area area area area area area area area area area .\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: very different city , said very differents , stronger told reuters at least three people .\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 3\n",
    "\n",
    "examples = [\n",
    "            \"오바마는 대통령이다.\",\n",
    "            \"시민들은 도시 속에 산다.\",\n",
    "            \"커피는 필요 없다.\",\n",
    "            \"일곱 명의 사망자가 발생했다.\"\n",
    "]\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                    dec_train[idx:idx+BATCH_SIZE],\n",
    "                    transformer,\n",
    "                    optimizer)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
    "\n",
    "for example in examples:\n",
    "    translate(example, transformer, ko_tokenizer, en_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ce6d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff2b2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
